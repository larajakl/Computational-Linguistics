{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larajakl/Computational-Linguistics/blob/main/homeexercise2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Home Exericse 2: Word Embeddings\n",
        "In this second home exercise, you will use the knowledge from Tutorial 3 to perform a more systematic evaluation of embeddings based on a small analogy dataset.\n",
        "\n",
        "In this notebook, please complete all instructions starting with üëã ‚öí in the code cell after the sign or provide your analysis in the text cell after the sign."
      ],
      "metadata": {
        "id": "N4_fSCGEAFZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Word2Vec Analogy-based Evaluation**"
      ],
      "metadata": {
        "id": "vnXNn2eL1jnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first need to load the pretrained embeddings and the dataset. The dataset can be found on [GitHub](https://github.com/dgromann/cl_intro_ws2024/blob/main/exercises/HomeExercise2.txt) and will be loaded directly from there."
      ],
      "metadata": {
        "id": "YHR4hkXKvd87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/dgromann/cl_intro_ws2024/raw/main/word2vec_embeddings.bin\n",
        "!wget !wget https://raw.githubusercontent.com/dgromann/cl_intro_ws2024/master/exercises/HomeExercise2.txt"
      ],
      "metadata": {
        "id": "kxwz_cPyW4lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we need to load the model with gensim so that we can access the embeddings."
      ],
      "metadata": {
        "id": "If_-whLgv9kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(\"word2vec_embeddings.bin\", binary=True)"
      ],
      "metadata": {
        "id": "1z4TAwF0v-8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we need to open the HomeExercise2.txt file that contains analogy pairs."
      ],
      "metadata": {
        "id": "88Q9RW2ZwHkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analogy = open(\"HomeExercise2.txt\", \"r\")\n",
        "analogy_lines = analogy.readlines()"
      ],
      "metadata": {
        "id": "saqImWrswKYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To look at the first few lines, the following code can be used. The analogies are grouped by categories that is indicated on the line before the anlogies are listed with a colon :. The last and fourth element of the line represents the true result we will use to evaluate the embedding model."
      ],
      "metadata": {
        "id": "X8fwdQjOxDR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "line_no = 0\n",
        "for line in analogy_lines:\n",
        "  line_no += 1\n",
        "  print(f\"Line number {line_no} with analogy {line}\")\n",
        "  if line_no == 5:\n",
        "    break"
      ],
      "metadata": {
        "id": "yKHVQpGbxGc7",
        "outputId": "40e3c00a-db3c-49f9-ab9b-e120ea23558a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line number 1 with analogy : capital-common-countries\n",
            "\n",
            "Line number 2 with analogy Athens Greece Baghdad Iraq\n",
            "\n",
            "Line number 3 with analogy Athens Greece Berlin Germany\n",
            "\n",
            "Line number 4 with analogy Athens Greece Cairo Egypt\n",
            "\n",
            "Line number 5 with analogy Athens Greece Canberra Australia\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí Systematically evaluate this simple word embedding model based on the entire analogy dataset. To do this:\n",
        "\n",
        "\n",
        "*   Use the analogy function from Tutorial 3 to obtain 'd'\n",
        "*   Compare 'd' with the true result from the `HomeExercise1.txt` file\n",
        "*   Calculate the accuracy for all analogies (how many times out of all attempts did the embedding model provide the correct result)\n",
        "*   Calculate the accuracy for each analogy category separately\n",
        "\n",
        "When parsing the file, pay attention to the lines indicated with the colon : that represent the analogy categories and not analogies.\n"
      ],
      "metadata": {
        "id": "a3xklUvEXbd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "# Example: Athens is to Greece as Baghdar is to ?\n",
        "# True result from file: Iraq\n",
        "# Model result also Iraq?"
      ],
      "metadata": {
        "id": "knGLoU0kXaZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparison: GloVe Analogy-based Evaluation**"
      ],
      "metadata": {
        "id": "bM-lxrQV15lF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step will consist of comparing this very small word2vec embedding model with a different small but more powerfull model available in gensim.\n",
        "\n",
        "All models and corpora available in gensim can be found [here](https://github.com/piskvorky/gensim-data).\n",
        "\n",
        "Since this model is considerably bigger than the tiny word2vec model, it takes some time to load when you run the following code cell."
      ],
      "metadata": {
        "id": "KN5pGa7JzT9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model_glove = api.load(\"glove-wiki-gigaword-100\")\n",
        "print(type(model))"
      ],
      "metadata": {
        "id": "noalz14AzkQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model can then be used exactly the same as the word2vec model, since gensim standardizes model access."
      ],
      "metadata": {
        "id": "kEWEOytj0hrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_glove[\"bread\"]"
      ],
      "metadata": {
        "id": "NmyLiSoF0s0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí  Run the same systematic analysis for this gensim model as for the word2vec model above. Which model performs better overall and in specific categories?"
      ],
      "metadata": {
        "id": "N-eMSsyO1PMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "dZk0eA3B1ZSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visual Comparison**\n",
        "\n",
        "As a final step, use the visualization from Tutorial 3 to visually output the two models based on the following words."
      ],
      "metadata": {
        "id": "r1b7CPN-2Clq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí  ‚ùì Do the clusters (groupings of embeddings) in the GloVe visualization differ substantially from the clusters in the word2vec visualization from Tutorial 3?"
      ],
      "metadata": {
        "id": "QWg0FNJG1aY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def display_pca_scatterplot(model, words):\n",
        "\n",
        "    word_vectors = np.array([model[w] for w in words])\n",
        "\n",
        "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
        "    for word, (x,y) in zip(words, twodim):\n",
        "        plt.text(x+0.05, y+0.05, word)"
      ],
      "metadata": {
        "id": "WaHuaINH2UJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_pca_scatterplot(model_glove,\n",
        "                        ['coffee', 'tea', 'beer', 'wine', 'water',\n",
        "                         'hamburger', 'pizza',  'sushi', 'meatballs',\n",
        "                         'dog', 'horse', 'cat', 'monkey', 'parrot', 'lizard',\n",
        "                         'france', 'germany', 'hungary',\n",
        "                         'school', 'college', 'university', 'institute'])"
      ],
      "metadata": {
        "id": "h5C4yZsN2lAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Provide your answer to the question on the clusters here.**"
      ],
      "metadata": {
        "id": "lbxcCxRB4Rvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bias in Embeddings**\n",
        "\n",
        "Language models and also embedding models tend to reflect on bias that is present in the textual data they were trained on. This can also be analyzed with embeddings by explicitly testing biased analogies.\n",
        "\n",
        "For instance, man is to doctor as woman is to ?\n",
        "\n",
        "The bias here is that professions tend to be assigned a specific gender, e.g. men are doctors and women are nurses.\n",
        "\n",
        "The same is true for cultures and cultural bias, e.g. Bratwurst or Sauerkraut and Germany.\n",
        "\n"
      ],
      "metadata": {
        "id": "fR022k6924H8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = model_glove.most_similar(positive=[\"doctor\", \"woman\"], negative=[\"man\"], topn=3)\n",
        "print(f\"man is to doctor as woman is to {result1}\")\n",
        "result2 = model_glove.most_similar(positive=[\"bratwurst\", \"france\"], negative=[\"germany\"], topn=3)\n",
        "print(f\"Germany is to Bratwurst as France is to {result2}\")"
      ],
      "metadata": {
        "id": "bdEoibPg4Ylz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí Try to come up with two biased analogies yourself and test if the GloVe and word2vec models suffers from this type of bias. Please try to be creative and do not just change woman to girl and man to boy or something similar."
      ],
      "metadata": {
        "id": "9S2HoyVE7hL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your biased analogies on both models here"
      ],
      "metadata": {
        "id": "IVvhsv5u7wHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}