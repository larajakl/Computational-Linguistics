{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "B4tdTuDs_3oz"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7180337a72a94b80ac456a27616d9a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97bdc4c4d0424526be38a6815072c3ca",
              "IPY_MODEL_3c0ab2be03d342efb5804514d8c28109",
              "IPY_MODEL_20f5adf579f640c6a44389b3633e85a8"
            ],
            "layout": "IPY_MODEL_eee091c89f6142769a8e861a58b546fe"
          }
        },
        "97bdc4c4d0424526be38a6815072c3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf95dc77d092480a9baf9973f076fe88",
            "placeholder": "​",
            "style": "IPY_MODEL_7007e145b4024c39874f9c3d6e056483",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3c0ab2be03d342efb5804514d8c28109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4ddc1ad0222464f823638a078196b07",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f0eac881ac74608b33a077e95780938",
            "value": 49
          }
        },
        "20f5adf579f640c6a44389b3633e85a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a32c68e8588843ab818e43841dca0ac1",
            "placeholder": "​",
            "style": "IPY_MODEL_d9e71d1d498b4b32802acd8a6ba6e638",
            "value": " 49.0/49.0 [00:00&lt;00:00, 1.20kB/s]"
          }
        },
        "eee091c89f6142769a8e861a58b546fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf95dc77d092480a9baf9973f076fe88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7007e145b4024c39874f9c3d6e056483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4ddc1ad0222464f823638a078196b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f0eac881ac74608b33a077e95780938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a32c68e8588843ab818e43841dca0ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e71d1d498b4b32802acd8a6ba6e638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2636b0dea9ab470f9dc9d4d435f318fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f3be46522fd4fda895347daa887a38e",
              "IPY_MODEL_8df098d8587d475bb3fb938eb7a3dd2d",
              "IPY_MODEL_c4d61adb692745fc81cd904b1986782d"
            ],
            "layout": "IPY_MODEL_e21807ddbbdc45af9933447d7bd43cc4"
          }
        },
        "7f3be46522fd4fda895347daa887a38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f530cd860eb49ea8613da6fea266a77",
            "placeholder": "​",
            "style": "IPY_MODEL_06eaa13f936c4e96b700abd586b581ac",
            "value": "config.json: 100%"
          }
        },
        "8df098d8587d475bb3fb938eb7a3dd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed75312ab3c348cca9cea8d223fd7713",
            "max": 465,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddc27f6c4ba9454883ddd21898f457d5",
            "value": 465
          }
        },
        "c4d61adb692745fc81cd904b1986782d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa7846756ad8407cb56052b22829fcdb",
            "placeholder": "​",
            "style": "IPY_MODEL_bba329818c194be7b41e98cbbc567e26",
            "value": " 465/465 [00:00&lt;00:00, 9.19kB/s]"
          }
        },
        "e21807ddbbdc45af9933447d7bd43cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f530cd860eb49ea8613da6fea266a77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06eaa13f936c4e96b700abd586b581ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed75312ab3c348cca9cea8d223fd7713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc27f6c4ba9454883ddd21898f457d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa7846756ad8407cb56052b22829fcdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bba329818c194be7b41e98cbbc567e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c2f6f1c036e4cccbb7ade51ba83d0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f66db33c85f74e96ac3e29582708eed8",
              "IPY_MODEL_0b1cb69b638042949c06471b30cdff59",
              "IPY_MODEL_f41a9970eaea4532bfbb0b9355cde3b0"
            ],
            "layout": "IPY_MODEL_39bb29ebdc9a42f2bd12f651d16abd01"
          }
        },
        "f66db33c85f74e96ac3e29582708eed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1804507d87494a0f8183ed4cf7964ec6",
            "placeholder": "​",
            "style": "IPY_MODEL_ea4bf6a7efbf4a64a1c6cfe100df4272",
            "value": "vocab.txt: 100%"
          }
        },
        "0b1cb69b638042949c06471b30cdff59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_822a23e26339495095362621af4b51ce",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5eb47bf3b813459aa3c5a01cc6a52f0f",
            "value": 213450
          }
        },
        "f41a9970eaea4532bfbb0b9355cde3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ca460d4e10f47779990b204a4ddcc92",
            "placeholder": "​",
            "style": "IPY_MODEL_0484316be95941bdb739b463aa2b2b7e",
            "value": " 213k/213k [00:00&lt;00:00, 2.65MB/s]"
          }
        },
        "39bb29ebdc9a42f2bd12f651d16abd01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1804507d87494a0f8183ed4cf7964ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea4bf6a7efbf4a64a1c6cfe100df4272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "822a23e26339495095362621af4b51ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eb47bf3b813459aa3c5a01cc6a52f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ca460d4e10f47779990b204a4ddcc92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0484316be95941bdb739b463aa2b2b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6db46fb42e9548b4bc3b4736ed62e1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06aa33ebc1894c4583d5eb4d4061f5f2",
              "IPY_MODEL_69ad89ae15264774952dde23578a362f",
              "IPY_MODEL_b4f66d900d3d4432917b2c01c1925fbb"
            ],
            "layout": "IPY_MODEL_4fbdf4503eb4426e9e6e6624c0eccc36"
          }
        },
        "06aa33ebc1894c4583d5eb4d4061f5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4210cf661be5452aa1b3ddc0f796d975",
            "placeholder": "​",
            "style": "IPY_MODEL_a904100f22ad495a930209cc05300646",
            "value": "tokenizer.json: 100%"
          }
        },
        "69ad89ae15264774952dde23578a362f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97c2499292c44d88b796081b78da72e0",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c47085ebcb748059ed8829ee6061a4f",
            "value": 435797
          }
        },
        "b4f66d900d3d4432917b2c01c1925fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61e41e1fa89341949b6ff4c7c283f0f1",
            "placeholder": "​",
            "style": "IPY_MODEL_4376df8b77f74610bcebc596bf11baa1",
            "value": " 436k/436k [00:00&lt;00:00, 2.87MB/s]"
          }
        },
        "4fbdf4503eb4426e9e6e6624c0eccc36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4210cf661be5452aa1b3ddc0f796d975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a904100f22ad495a930209cc05300646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97c2499292c44d88b796081b78da72e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c47085ebcb748059ed8829ee6061a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61e41e1fa89341949b6ff4c7c283f0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4376df8b77f74610bcebc596bf11baa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larajakl/Computational-Linguistics/blob/main/tutorial4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 4: Introduction to Computational Linguistics\n",
        "\n",
        "This is the fourth tutorial with practical exercises for the lecture Introduction to Computational Linguistics in the winter semester 2024. Hands-on exercises are marked with 👋 ⚒ and questions are marked with ❓. Remember to first **store this notebook** in your Drive or GitHub."
      ],
      "metadata": {
        "id": "gZ9Hk2B4Sq3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lesson 1: Hugging Face Tutorial**\n",
        "\n",
        "Hugging Face is a platform that provides access to models, datasets, and metrics. It mostly provides implementations in PyTorch and TensorFlow.\n",
        "\n",
        "\n",
        "In this tutorial, we will first focus on tokenizers and models. Afterwards, we will look into fine-tuning models. For further reading and to help your project, please check the [Hugging Face Documentation and Tutorials](https://huggingface.co/docs/transformers/index).\n",
        "\n",
        "As a first step, we need to install the libraries `transformers`to load any transformer models and the library `datasets`to have access to all the Hugging Face datasets."
      ],
      "metadata": {
        "id": "Mg3rQ5egSsYZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chrmoR_USnc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd243db4-f91f-4f2b-c9fa-85d9e281cd8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: bertviz in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.66.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from bertviz) (1.35.64)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.32.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from bertviz) (2024.9.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bertviz) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.64 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (1.35.64)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (0.10.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.64->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->bertviz) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.64->boto3->bertviz) (1.16.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install bertviz transformers\n",
        "!pip install accelerate --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using Hugging Face, there are two very important objects to be initialized, a **tokenizer** and a **model**.\n",
        "\n",
        "\n",
        "\n",
        "*   **Tokenizer**: converts strings or text to lists of vocabularies required by the model\n",
        "*   **Model**: takes the tokenized datasets, i.e., the vocabulary ids, and can be trained to produce a prediction\n",
        "\n",
        "We will start looking into the tokenizer first."
      ],
      "metadata": {
        "id": "R1fljaUSVMSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer\n",
        "\n",
        "Pre-trained language models are implemented with a tokenizer that processes their input. You can either access teoknizers with the class specific to the model, i.e., DistilBERT, or use the `AutoTokenizer` class that defaults to the optimized tokenizer of the models. The alternative would be to use `DistilBertTokenizerFast` directly."
      ],
      "metadata": {
        "id": "lwZUhjEcuW10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-cased\")\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "id": "4I30_An9uZwX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "7180337a72a94b80ac456a27616d9a35",
            "97bdc4c4d0424526be38a6815072c3ca",
            "3c0ab2be03d342efb5804514d8c28109",
            "20f5adf579f640c6a44389b3633e85a8",
            "eee091c89f6142769a8e861a58b546fe",
            "bf95dc77d092480a9baf9973f076fe88",
            "7007e145b4024c39874f9c3d6e056483",
            "e4ddc1ad0222464f823638a078196b07",
            "3f0eac881ac74608b33a077e95780938",
            "a32c68e8588843ab818e43841dca0ac1",
            "d9e71d1d498b4b32802acd8a6ba6e638",
            "2636b0dea9ab470f9dc9d4d435f318fa",
            "7f3be46522fd4fda895347daa887a38e",
            "8df098d8587d475bb3fb938eb7a3dd2d",
            "c4d61adb692745fc81cd904b1986782d",
            "e21807ddbbdc45af9933447d7bd43cc4",
            "5f530cd860eb49ea8613da6fea266a77",
            "06eaa13f936c4e96b700abd586b581ac",
            "ed75312ab3c348cca9cea8d223fd7713",
            "ddc27f6c4ba9454883ddd21898f457d5",
            "fa7846756ad8407cb56052b22829fcdb",
            "bba329818c194be7b41e98cbbc567e26",
            "6c2f6f1c036e4cccbb7ade51ba83d0b3",
            "f66db33c85f74e96ac3e29582708eed8",
            "0b1cb69b638042949c06471b30cdff59",
            "f41a9970eaea4532bfbb0b9355cde3b0",
            "39bb29ebdc9a42f2bd12f651d16abd01",
            "1804507d87494a0f8183ed4cf7964ec6",
            "ea4bf6a7efbf4a64a1c6cfe100df4272",
            "822a23e26339495095362621af4b51ce",
            "5eb47bf3b813459aa3c5a01cc6a52f0f",
            "6ca460d4e10f47779990b204a4ddcc92",
            "0484316be95941bdb739b463aa2b2b7e",
            "6db46fb42e9548b4bc3b4736ed62e1a8",
            "06aa33ebc1894c4583d5eb4d4061f5f2",
            "69ad89ae15264774952dde23578a362f",
            "b4f66d900d3d4432917b2c01c1925fbb",
            "4fbdf4503eb4426e9e6e6624c0eccc36",
            "4210cf661be5452aa1b3ddc0f796d975",
            "a904100f22ad495a930209cc05300646",
            "97c2499292c44d88b796081b78da72e0",
            "7c47085ebcb748059ed8829ee6061a4f",
            "61e41e1fa89341949b6ff4c7c283f0f1",
            "4376df8b77f74610bcebc596bf11baa1"
          ]
        },
        "outputId": "5d958fec-0bd5-4271-c33d-1573537aa4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7180337a72a94b80ac456a27616d9a35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2636b0dea9ab470f9dc9d4d435f318fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c2f6f1c036e4cccbb7ade51ba83d0b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6db46fb42e9548b4bc3b4736ed62e1a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBertTokenizerFast(name_or_path='distilbert/distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now input a sample sentence to the tokenizer to create a list of vocabularies with related ids and see how to access the ids the tokenizer provides.\n",
        "\n",
        "The resulting datatype is called ` BatchEncoding`, which holds the output of a pretrained batch encoding method and is derived from a Python dictionary.\n",
        "\n",
        "**❓** Why did the tokenizer generate more IDs than there are words in the input sentence?"
      ],
      "metadata": {
        "id": "TPrfty_rvDn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = \"Hugging Face is great!\"\n",
        "tokenized_inputs = tokenizer(input_str)\n",
        "\n",
        "# Two ways to access:\n",
        "print(tokenized_inputs.input_ids)\n",
        "print(tokenized_inputs[\"input_ids\"])"
      ],
      "metadata": {
        "id": "ysAbiGnAMt0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0db1418-3e4e-4ccc-8a14-b54705511e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 20164, 10932, 10289, 1110, 1632, 106, 102]\n",
            "[101, 20164, 10932, 10289, 1110, 1632, 106, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization is a process of several steps. First the string is tokenized, which is slightly different from the tokenization of Tutorial 2, and then the tokens converted to IDs as shown below.\n",
        "\n",
        "The tokens shown represent so-called wordpieces, which is the result of a subword tokenization algorithm underlying the AutoTokenizer algorithms. The algorithm is called WordPiece and was developed by Google when pretraining BERT. The characters `##` are a WordPiece prefix to indicate wordpieces inside a word. See the following tutorial for [more information on WordPiece](https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt)."
      ],
      "metadata": {
        "id": "3J-XD6yNN_mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = tokenizer.tokenize(input_str)\n",
        "print(f\"Tokens of the input sequence: {input_tokens}\")\n",
        "input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
        "print(f\"IDs assigned to the intput sequence: {input_ids}\")"
      ],
      "metadata": {
        "id": "qHDezw-aOgiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094d6e10-5f38-4583-ebaa-cd38aca4ea2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens of the input sequence: ['Hu', '##gging', 'Face', 'is', 'great', '!']\n",
            "IDs assigned to the intput sequence: [20164, 10932, 10289, 1110, 1632, 106]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert existing IDs back to text, we can use the function `decode`.\n",
        "\n"
      ],
      "metadata": {
        "id": "qqLgJD9Ype6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = tokenizer.decode(input_ids)\n",
        "print(decoded)"
      ],
      "metadata": {
        "id": "YZ_PXvxJpi1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c609c3e6-b96b-420a-bb61-6e47c6c7d202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face is great!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👋 ⚒ Decode the original tokenized sequence `tokenized_inputs` in the code cell below. First, find out and print which datatype this variable is. Remember that the `decode` function only takes IDs as input."
      ],
      "metadata": {
        "id": "KGZnC7B9qm7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the original variable tokenized_inputs\n",
        "print(type(tokenized_inputs))\n",
        "print(tokenized_inputs)  # looks like dictionary. we don't care about attention_mask now because we didnt train it\n",
        "# it is batch encoding and it looks like a dictionary so I can treat it like a dictionary!\n",
        "\n",
        "print(tokenizer.decode(tokenized_inputs[\"input_ids\"]))  # another way to go from ids to sequence. closer to input ids than other way we did before. just\n",
        "# different ways to get output from tokenizer."
      ],
      "metadata": {
        "id": "VcnegkXyqor0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621be291-33d2-4ecd-c9d3-2822fda8161a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
            "{'input_ids': [101, 20164, 10932, 10289, 1110, 1632, 106, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "[CLS] Hugging Face is great! [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the mystery of more IDs than visible words in the input sequence can partially be answered by the tokenization and by the fact that a special token [CLS] at the beginning of a sequence and [SEP] at the end of a sequence are added for BERT-type models.\n",
        "\n",
        "Another way to reach a similar result as with `decode` can be seen in the next code cell. The difference is that with this method the special tokens are also represented."
      ],
      "metadata": {
        "id": "by0OrtRepqho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer._tokenizer.encode(input_str)  # useful if I need tokens for something or if I need more details on how tokenization works\n",
        "special = inputs.tokens\n",
        "print(special)\n",
        "\n",
        "# basically what i need to know is how to tokenise and how to get my input again"
      ],
      "metadata": {
        "id": "SUznB96BVmTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4d00c4-7c1b-4b68-c89d-02f5459d06a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'Hu', '##gging', 'Face', 'is', 'great', '!', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the output of the tokenizer to a PyTorch tensor can be done easily by adding `return_tensor = pt`to the tokenization process. Compare the following output with the output of the previous code cell."
      ],
      "metadata": {
        "id": "tWaFF3eLt0PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = tokenizer(\"Hugging Face is great!\", return_tensors=\"pt\")  # useful if I want to work with pytorch tensors. this automatically gives me pytorch tensor.\n",
        "print(model_inputs)"
      ],
      "metadata": {
        "id": "YupZO-tbt-DT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea5d994-bab7-4070-ec7b-fb4852a0fb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 20164, 10932, 10289,  1110,  1632,   106,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also tokenize a number of sentences at once. To ease processing, it is common to make all sentences of the same length by padding, that is, adding the `PAD' token to sequences to turn them all into sequences of the same length."
      ],
      "metadata": {
        "id": "OtpTYQpTuddt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = tokenizer([\"Hugging Face is great!\",  # batches used to separate dataset into batches (not sentences) and use these when training.\n",
        "                         \"The quick brown fox jumps over the lazy dog.\",\n",
        "                         \"We are learning to fine-tune models.\",\n",
        "                         ],\n",
        "                         return_tensors=\"pt\",\n",
        "                         padding=True,\n",
        "                         truncation=True)\n",
        "print(model_inputs)\n",
        "print(tokenizer.pad_token, tokenizer.pad_token_id)\n",
        "\n",
        "# output automatically produces 0s because of setting padding True. truncation means it would cut off sequences that are\n",
        "# too long for the model settings -> these parts are then lost -> older models so amount of words for input at once is\n",
        "# shorter -> padding and truncation kind of opposites!"
      ],
      "metadata": {
        "id": "aznHyJvaudlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a499d4a4-9bfd-44ab-f4bd-7af4f0a185ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 20164, 10932, 10289,  1110,  1632,   106,   102,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,  1109,  3613,  3058, 17594, 15457,  1166,  1103, 16688,  3676,\n",
            "           119,   102],\n",
            "        [  101,  1284,  1132,  3776,  1106,  2503,   118,  9253,  3584,   119,\n",
            "           102,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
            "[PAD] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to decode a whole set of sentences, we can use the function batch decode."
      ],
      "metadata": {
        "id": "0G70AWabvQ3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.batch_decode(model_inputs.input_ids))  #in our case we have a batch of 3 sentences\n",
        "print()\n",
        "print(\"Omitting special characters when decoding:\")\n",
        "print(tokenizer.batch_decode(model_inputs.input_ids, skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "65a-vRCUvQ_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c12e354-fedf-4da6-978b-6e6e05f1028f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS] Hugging Face is great! [SEP]']\n",
            "\n",
            "Omitting special characters when decoding:\n",
            "['Hugging Face is great!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "The way models are initialized in Hugging Face is achieved with a similar code as initializing Tokenizers. There are model-specific classes or the AutoModel classes, which is preferable when comparing different models.\n",
        "\n",
        "Hugging Face automatically sets up the architecture you need for a specific task when you specify the model class, e.g. `AutoModelForSequenceClassification` respectively the model-specific `DistilBertForSequenceClassification` need to be used when you want to do sentiment analysis, question-answering, etc. For training a model on the masked language task, you need to use other classes, such as `DistilBertForMaskedLM`. More details can be found [here](https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt).\n",
        "\n",
        "\n",
        "The main three types of models are:\n",
        "\n",
        "\n",
        "*   Encoders, e.g. BERT\n",
        "*   Decoders, e.g. GPT-2\n",
        "*   Encoder-Decoders, e.g. BART or T5, which are Machine Translation (MT) models\n",
        "\n"
      ],
      "metadata": {
        "id": "DHl1IZ6Xv_mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-cased', num_labels=2)"
      ],
      "metadata": {
        "id": "SrlZsU1DxcM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get this warning because the sequence classification parameters of the model have not yet been trained.\n",
        "\n",
        "To input a string into a model requires it to be tokenized first. Then the input is very easy. The output consists of two classes since we indicated `num_labels = 2`."
      ],
      "metadata": {
        "id": "OJDH8ZR4x2f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model_inputs = tokenizer(input_str, return_tensors=\"pt\")\n",
        "\n",
        "model_outputs = model(**model_inputs)\n",
        "\n",
        "print(model_inputs)\n",
        "print(model_outputs)\n",
        "\n",
        "print(\"To convert the logits outputs to probabilities, we can use softmax again:\", torch.softmax(model_outputs.logits, dim=1))"
      ],
      "metadata": {
        "id": "dfwklamOx7o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have two output classes for a binary classification task, which is only due to the fact how Hugging Face calculates the loss.\n",
        "\n",
        "We can now use the model logits to calculate the loss, i.e., go from the model predictions to the intended label and calculate the difference with any suitable loss function. We will first do this using PyTorch.\n",
        "\n",
        "For this example, we pretend that Label 1 is the correct label and pass this information to a loss function. Since this is a binary classification task, it makes more sense to use sigmoid or cross-entropy rather than softmax as a loss function."
      ],
      "metadata": {
        "id": "14VqXP-3zHIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = torch.tensor([1])\n",
        "loss = torch.nn.functional.cross_entropy(model_outputs.logits, label)\n",
        "print(loss)\n",
        "loss.backward()\n",
        "\n",
        "# You can get the parameters\n",
        "list(model.named_parameters())[0]"
      ],
      "metadata": {
        "id": "TpRVsTqEzF8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also calculate the loss directly with Hugging Face."
      ],
      "metadata": {
        "id": "d1_AKNztz5CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = tokenizer(input_str, return_tensors=\"pt\")\n",
        "\n",
        "labels = ['NEGATIVE', 'POSITIVE']\n",
        "model_inputs['labels'] = torch.tensor([1])\n",
        "\n",
        "model_outputs = model(**model_inputs)\n",
        "\n",
        "\n",
        "print(model_outputs)\n",
        "print()\n",
        "print(\"Model predictions: \", labels[model_outputs.logits.argmax()])"
      ],
      "metadata": {
        "id": "czgLomWB0CGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze in more detail what happens during training, we can visualize the attention weights and hidden states.\n",
        "\n",
        "We can use BertViz to explicitly see the change of the attention weights for each layer."
      ],
      "metadata": {
        "id": "S_X87Uks2Jes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bertviz import model_view, head_view\n",
        "\n",
        "# We need to initialize the model with setting output attentions explicitly to True\n",
        "model = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-cased', num_labels=2, output_attentions=True)\n",
        "# We then need to explicitly encode the tokens\n",
        "inputs = tokenizer.encode(input_str, return_tensors='pt')\n",
        "outputs = model(inputs)\n",
        "\n",
        "attention = outputs[-1]\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[0])\n",
        "head_view(attention, tokens)"
      ],
      "metadata": {
        "id": "d_FnE4uN1X-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is also another method to analyze hidden states and attention weights."
      ],
      "metadata": {
        "id": "lGVmD5aC2dgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"distilbert/distilbert-base-cased\", output_attentions=True, output_hidden_states=True)\n",
        "model.eval()\n",
        "\n",
        "model_inputs = tokenizer(input_str, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    model_output = model(**model_inputs)\n",
        "\n",
        "\n",
        "print(\"Hidden state size (per layer):  \", model_output.hidden_states[0].shape)\n",
        "print(\"Attention head size (per layer):\", model_output.attentions[0].shape)     # (layer, batch, query_word_idx, key_word_idxs)\n",
        "                                                                               # y-axis is query, x-axis is key\n",
        "print(model_output)"
      ],
      "metadata": {
        "id": "0rv995SK2nHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(model_inputs.input_ids[0])\n",
        "print(tokens)\n",
        "\n",
        "n_layers = len(model_output.attentions)\n",
        "n_heads = len(model_output.attentions[0][0])\n",
        "fig, axes = plt.subplots(6, 12)\n",
        "fig.set_size_inches(18.5*2, 10.5*2)\n",
        "for layer in range(n_layers):\n",
        "    for i in range(n_heads):\n",
        "        axes[layer, i].imshow(model_output.attentions[layer][0, i])\n",
        "        axes[layer][i].set_xticks(list(range(8))) # 8 is the number of wordpieces in our example\n",
        "        axes[layer][i].set_xticklabels(labels=tokens, rotation=\"vertical\")\n",
        "        axes[layer][i].set_yticks(list(range(8))) # 8 is the number of wordpieces in our example\n",
        "        axes[layer][i].set_yticklabels(labels=tokens)\n",
        "\n",
        "        if layer == 5:\n",
        "            axes[layer, i].set(xlabel=f\"head={i}\")\n",
        "        if i == 0:\n",
        "            axes[layer, i].set(ylabel=f\"layer={layer}\")\n",
        "\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jr4zM6px2qfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning\n",
        "\n",
        "For your final projects, you will need to finetune a pretrained language model.\n",
        "\n",
        "In addition to models, Hugging Face also provides a large repository of datasets."
      ],
      "metadata": {
        "id": "hPCP2t1A3-xD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading the data**\n",
        "\n",
        "For this example we are going to work with the `imdb` dataset, which is a Large Movie Review Dataset.\n",
        "\n",
        "We will use the native PyTorch version to load the dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NkHrk0dn57r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "imdb_dataset = load_dataset(\"imdb\")\n",
        "\n",
        "\n",
        "# Just take the first 50 tokens for speed on cpu\n",
        "def truncate(example):\n",
        "    return {\n",
        "        'text': \" \".join(example['text'].split()[:50]),\n",
        "        'label': example['label']\n",
        "    }\n",
        "\n",
        "# Take 128 random examples for train and 32 validation\n",
        "small_imdb_dataset = DatasetDict(\n",
        "    train=imdb_dataset['train'].shuffle(seed=24).select(range(128)).map(truncate),\n",
        "    val=imdb_dataset['train'].shuffle(seed=24).select(range(128, 160)).map(truncate),\n",
        ")"
      ],
      "metadata": {
        "id": "1xIMqRUF4STK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_imdb_dataset"
      ],
      "metadata": {
        "id": "5Tu3L15k67EA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "👋 ⚒ Print the first ten examples of the training dataset of the `small_imdb_dataset`."
      ],
      "metadata": {
        "id": "e4rpftK8PQWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "62bhqrp85SfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the data for use in PyTorch\n",
        "\n",
        "We need to prepare the dataset as input to the model by tokenization and padding. We also need to:\n",
        "\n",
        "1. Remove the `text` column because the model does not accept raw text as an input:\n",
        "\n",
        "    ```py\n",
        "    >>> tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "    ```\n",
        "\n",
        "2. Rename the `label` column to `labels` because the model expects the argument to be named `labels`:\n",
        "\n",
        "    ```py\n",
        "    >>> tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "    ```\n",
        "\n",
        "3. Set the format of the dataset to return PyTorch tensors instead of lists:\n",
        "\n",
        "    ```py\n",
        "    >>> tokenized_datasets.set_format(\"torch\")\n",
        "    ```"
      ],
      "metadata": {
        "id": "1mMv59IY7PRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=True, truncation=True)\n",
        "\n",
        "small_tokenized_dataset = small_imdb_dataset.map(tokenize_function, batched=True, batch_size=16)\n",
        "small_tokenized_dataset = small_tokenized_dataset.remove_columns([\"text\"])\n",
        "small_tokenized_dataset = small_tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "small_tokenized_dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "4v2E6JSH7TVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now check what the first two sequences of the tokenized training dataset looks like."
      ],
      "metadata": {
        "id": "o2CZOypm7vgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_tokenized_dataset['train'][0:2]"
      ],
      "metadata": {
        "id": "kfypRDaJ7vmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then create a `DataLoader` for your training and test datasets so we can iterate over batches of data:"
      ],
      "metadata": {
        "id": "ilGgIfsv8ewL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(small_tokenized_dataset['train'], batch_size=16)\n",
        "eval_dataloader = DataLoader(small_tokenized_dataset['val'], batch_size=16)"
      ],
      "metadata": {
        "id": "LdbHUcna8coc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training**\n",
        "\n",
        "Hugging Face models also use `torch.nn.Module` like you did in Tutorial 3, which means backpropagation happens the same way and the same optimizers can be used. Hugging Face includes optimizers and learning rate schedules, i.e., changes along the training process, to train Transformer models.\n",
        "\n",
        "With Stochastic Gradient Descent the learning rate does not change during training. Adam represents an optimizer that extends SGD by providing an Adaptive Gradient Algorithm (AdaGrad) and an adaptation depending on the recent magnitude of gradients called Root Mean Square Propagation (RMSProp). For more details on different optimizers, see for instance [this information](https://www.ruder.io/optimizing-gradient-descent/#adam).\n"
      ],
      "metadata": {
        "id": "97g8NNEq8pxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop with Hugging Face Trainer\n",
        "\n",
        "A [Hugging Face tutorial](https://huggingface.co/docs/transformers/training) on both variants of training is available. Here we will use this `Trainer` class that covers most needs.\n",
        "\n",
        "Just to be sure tht we have the right settings, we load the dataset again and tokenize it."
      ],
      "metadata": {
        "id": "Zgns-iz8IwSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "imdb_dataset = load_dataset(\"imdb\")\n",
        "# we had loaded the imdb dataset already above - if not, outcomment this line\n",
        "# Make sure you have the right tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-cased\")\n",
        "\n",
        "\n",
        "# Just take the first 50 tokens for speed on CPU\n",
        "def truncate(example):\n",
        "    return {\n",
        "        'text': \" \".join(example['text'].split()[:100]),\n",
        "        'label': example['label']\n",
        "    }\n",
        "\n",
        "# Take 128 random examples for train and 32 validation\n",
        "small_imdb_dataset = DatasetDict(\n",
        "    train=imdb_dataset['train'].shuffle(seed=24).select(range(128)).map(truncate),\n",
        "    val=imdb_dataset['train'].shuffle(seed=24).select(range(128, 160)).map(truncate),\n",
        ")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=True, truncation=True)\n",
        "\n",
        "small_tokenized_dataset = small_imdb_dataset.map(tokenize_function, batched=True, batch_size=16)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "psOqoDYvJBME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can specify all the training hyperparameters by using the `TrainningArguments`class, which is detailed [here](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments).\n",
        "\n",
        "The `Trainer` then performs the training und you can pass all the arguments to this class, even model checkpoints to resume training later. What was the validation part in the loop above is now the `compute_metrics` function."
      ],
      "metadata": {
        "id": "Y5cD7HihKNRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-cased', num_labels=2)\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "arguments = TrainingArguments(\n",
        "    output_dir=\"sample_cl_trainer\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_steps=8,\n",
        "    num_train_epochs=5,\n",
        "    eval_strategy=\"epoch\", # run validation at the end of each epoch\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to='none',\n",
        "    seed=224\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Called at the end of validation. Gives accuracy\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # calculates the accuracy\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=arguments,\n",
        "    train_dataset=small_tokenized_dataset['train'],\n",
        "    eval_dataset=small_tokenized_dataset['val'], # change to test when you do your final evaluation!\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "mDOF6X5LKNYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "OU0IMQaINtC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the training has been completed, evaluate the model, which is very easy with Hugging Face."
      ],
      "metadata": {
        "id": "2JxJn8y7EUWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.predict(small_tokenized_dataset['val'])\n",
        "print(results)"
      ],
      "metadata": {
        "id": "xRYZ6XXyOV9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we want to load the fine-tuned model for evaluation. We can load our models just like we load models from Hugging Face only that we need to pass the path to our models to the function `from_pretrained()`. We had 24 training steps (3 epochs times 8, where the 8 is the total number of training data (128) divided by the batch size (16)) so we can load a checkpoint for each of these steps.  "
      ],
      "metadata": {
        "id": "o-awP91-OcXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_str = \"I love this movie!\"\n",
        "\n",
        "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(\"sample_cl_trainer/checkpoint-40\")\n",
        "model_inputs = tokenizer(test_str, return_tensors=\"pt\")\n",
        "prediction = torch.argmax(fine_tuned_model(**model_inputs).logits)\n",
        "print([\"NEGATIVE\", \"POSITIVE\"][prediction])"
      ],
      "metadata": {
        "id": "DQ3QfFHjASxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop in PyTorch\n",
        "\n",
        "First, we will use native PyTorch for the training loop and training, since it is more transparent than the built-in Hugging Face functions.\n",
        "\n",
        "In this example we are going to use AdamW Optimizer, an extension of Adam with weight decay. And we're using a linear learning rate scheduler, which reduces the learning rate a little bit after each training step over the course of training.\n",
        "\n",
        "Let's load our model, optimizer, and learning rate scheduler. For this we need to the basic hyperparameters of the number of epochs we wish to train for and the number of training steps that depends on the size of the training dataset. We again get the same warning as before about this model not having been trained on sequence classification.\n",
        "\n",
        "To keep track of your training progress, use the [tqdm](https://tqdm.github.io/) library to add a progress bar over the number of training steps.\n",
        "\n",
        "We we also include a validation step that test the current state of the model on the validation dataset and saves a version of the model called `checkpoint`. To save the different model states as checkpoints, we first create a folder called checkpoints.  \n",
        "\n",
        "You might also want to consider early stopping, that is, interrupting the training loop when a certain threshold (value) has been reached. More information on that can be found [here](https://huggingface.co/docs/transformers/main_classes/callback#transformers.TrainerCallback)."
      ],
      "metadata": {
        "id": "B4tdTuDs_3oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-cased\", num_labels=5)\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = 3 * len(train_dataloader)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
      ],
      "metadata": {
        "id": "unJR1eVh-gNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last you can specify to use a `GPU`if you have access to one, e.g. on Colab, or else use a `CPU` if there is no access. Today, we will only train with `CPU`so no need to run the following cell."
      ],
      "metadata": {
        "id": "BgjoAGsQ_lI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "#model.to(device)"
      ],
      "metadata": {
        "id": "Oz0ioe-T_kxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints"
      ],
      "metadata": {
        "id": "njZhehhSCrdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        #batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    for batch_i, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            output = model(**batch)\n",
        "        loss += output.loss\n",
        "\n",
        "    avg_val_loss = loss / len(eval_dataloader)\n",
        "    print(f\"Validation loss: {avg_val_loss}\")\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        print(\"Saving checkpoint!\")\n",
        "        best_val_loss = avg_val_loss\n",
        "        model.save_pretrained(f\"checkpoints/epoch_{epoch}.pt\")AutoTokenizer"
      ],
      "metadata": {
        "id": "TvGKMoKFAApB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}