{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a3a2eff58da49179229c7c83bd33fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c590b1c178e49a89dab3989acb59417",
              "IPY_MODEL_ef2b85c949ca4cbabc0a5c68b12df4f6",
              "IPY_MODEL_d7d0784a3f584c368fa9d14239a036d8"
            ],
            "layout": "IPY_MODEL_db99b16b6c764df59bbf66fecfda1e9d"
          }
        },
        "0c590b1c178e49a89dab3989acb59417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12d8dbd6ab5e4860ad5a133857f2b36c",
            "placeholder": "​",
            "style": "IPY_MODEL_1e9cd34058a04d4b8d2aa450ad0d04c1",
            "value": "Map: 100%"
          }
        },
        "ef2b85c949ca4cbabc0a5c68b12df4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce3b2dbd631425c8773746520c8465c",
            "max": 187,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e43fa36e3f045c0bf24c8d82f5bbb7b",
            "value": 187
          }
        },
        "d7d0784a3f584c368fa9d14239a036d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a7907f686074f7d9580f6fa2814548a",
            "placeholder": "​",
            "style": "IPY_MODEL_b2a258b98ef04389b4a48708548b12f1",
            "value": " 187/187 [00:00&lt;00:00, 838.37 examples/s]"
          }
        },
        "db99b16b6c764df59bbf66fecfda1e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d8dbd6ab5e4860ad5a133857f2b36c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9cd34058a04d4b8d2aa450ad0d04c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dce3b2dbd631425c8773746520c8465c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e43fa36e3f045c0bf24c8d82f5bbb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a7907f686074f7d9580f6fa2814548a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a258b98ef04389b4a48708548b12f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59a32f6e4ecf4d2ba8ad1f4c13f834ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_142eb308a3864a599629e72b39730b36",
              "IPY_MODEL_2efc8d841d094650b7acae60ad8b488c",
              "IPY_MODEL_eef9c342e77c41889ac91c4a6a0de690"
            ],
            "layout": "IPY_MODEL_6bdc228fbcf14f769febccccfb4b8ca2"
          }
        },
        "142eb308a3864a599629e72b39730b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e11fd05f2a9040309abcdf7cf455423e",
            "placeholder": "​",
            "style": "IPY_MODEL_f9ba1b6013824db89107939ed2d3f02f",
            "value": "Map: 100%"
          }
        },
        "2efc8d841d094650b7acae60ad8b488c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4bde59245b04319bc9cc71b26af1019",
            "max": 187,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd6c82a1b9b42878cfe5f4072165064",
            "value": 187
          }
        },
        "eef9c342e77c41889ac91c4a6a0de690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a62d01551f24793a85197e0bb82caa7",
            "placeholder": "​",
            "style": "IPY_MODEL_e809c7863bae4e5ab1b440081e6a5e5d",
            "value": " 187/187 [00:00&lt;00:00, 642.03 examples/s]"
          }
        },
        "6bdc228fbcf14f769febccccfb4b8ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e11fd05f2a9040309abcdf7cf455423e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ba1b6013824db89107939ed2d3f02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4bde59245b04319bc9cc71b26af1019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd6c82a1b9b42878cfe5f4072165064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a62d01551f24793a85197e0bb82caa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e809c7863bae4e5ab1b440081e6a5e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larajakl/Computational-Linguistics/blob/main/Project_Lara_JAKL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfvys8hUc0FJ",
        "outputId": "27099d62-728f-4384-cb14-3bf4d8eaf1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Requirement already satisfied: optuna-integration[pytorch_lightning] in /usr/local/lib/python3.11/dist-packages (4.2.1)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optuna-integration[pytorch_lightning]) (4.2.0)\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.11/dist-packages (from optuna-integration[pytorch_lightning]) (2.5.0.post0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning->optuna-integration[pytorch_lightning]) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning->optuna-integration[pytorch_lightning]) (2024.9.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning->optuna-integration[pytorch_lightning]) (0.11.9)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning->optuna-integration[pytorch_lightning]) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning->optuna-integration[pytorch_lightning]) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning->optuna-integration[pytorch_lightning]) (1.6.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning->optuna-integration[pytorch_lightning]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning->optuna-integration[pytorch_lightning]) (4.12.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning->optuna-integration[pytorch_lightning]) (2.5.0.post0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[pytorch_lightning]) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[pytorch_lightning]) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[pytorch_lightning]) (1.26.4)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[pytorch_lightning]) (2.0.37)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[pytorch_lightning]) (1.3.8)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning->optuna-integration[pytorch_lightning]) (3.11.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning->optuna-integration[pytorch_lightning]) (75.1.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[pytorch_lightning]) (3.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->optuna-integration[pytorch_lightning]) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->optuna-integration[pytorch_lightning]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->optuna-integration[pytorch_lightning]) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->optuna-integration[pytorch_lightning]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->optuna-integration[pytorch_lightning]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->optuna-integration[pytorch_lightning]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->optuna-integration[pytorch_lightning]) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning->optuna-integration[pytorch_lightning]) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->optuna-integration[pytorch_lightning]) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install accelerate --upgrade\n",
        "!pip install optuna\n",
        "!pip install optuna-integration[pytorch_lightning]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from transformers import set_seed\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "id": "NbU_Zj4ndE2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"mrjunos/depression-reddit-cleaned\")\n",
        "\n",
        "set_seed(24)"
      ],
      "metadata": {
        "id": "hpQXiCzKdHtK",
        "outputId": "1d44abc8-13cd-46d6-d0db-748e0e137194",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check distribution of labels in full dataset:\n",
        "\n",
        "full_label_distribution = Counter(dataset['train']['label'])\n",
        "print(\"Full dataset label distribution:\", full_label_distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXb3rLq0VujZ",
        "outputId": "e4513d4e-6109-4518-8496-9fac9e6e128c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset label distribution: Counter({0: 3900, 1: 3831})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncation function and shuffling and splitting of dataset:\n",
        "def truncate(example):\n",
        "    return {\n",
        "        'text': \" \".join(example['text'].split()[:300]),\n",
        "        'label': example['label']\n",
        "    }\n",
        "\n",
        "# Random examples for train, validation and test\n",
        "# Limit the dataset to the first 200 entries, JUST FOR NOW (ADAPT THESE LINES LATER)\n",
        "subset_dataset = dataset['train'].shuffle(seed=24).select(range(1250))\n",
        "# Define the train/val/test split proportions:\n",
        "train_ratio, val_ratio = 0.7, 0.15  # 70% train, 15% val, 15% test\n",
        "# Shuffle the dataset once:\n",
        "shuffled_dataset = subset_dataset.shuffle(seed=24)\n",
        "# Compute the split indices:\n",
        "total_size = len(shuffled_dataset)\n",
        "train_end = int(train_ratio * total_size)\n",
        "val_end = train_end + int(val_ratio * total_size)\n",
        "# Create splits:\n",
        "train = shuffled_dataset.select(range(train_end)).map(truncate)\n",
        "val = shuffled_dataset.select(range(train_end, val_end)).map(truncate)\n",
        "test = shuffled_dataset.select(range(val_end, total_size)).map(truncate)\n",
        "\n",
        "# Print the sizes of the splits:\n",
        "print(f\"Train size: {len(train)}, Validation size: {len(val)}, Test size: {len(test)}\")\n",
        "\n",
        "dataset_dict = DatasetDict({\n",
        "    \"train\": train,\n",
        "    \"val\": val,\n",
        "    \"test\": test\n",
        "})"
      ],
      "metadata": {
        "id": "ndIlGk7gddMe",
        "outputId": "c1dff836-e266-4da1-d245-93d31f75f5a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 875, Validation size: 187, Test size: 188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check structure of dataset:\n",
        "print(shuffled_dataset)\n",
        "print(dataset_dict)"
      ],
      "metadata": {
        "id": "8T2YiuqkkER9",
        "outputId": "b2ac291b-36cf-4b4b-f8dd-5494f184de91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 1250\n",
            "})\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 875\n",
            "    })\n",
            "    val: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 187\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 188\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Tokenizer DistilBERT cased\n",
        "tokenizer_distilbert = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-cased\")\n",
        "\n",
        "def tokenize_function_distilbert(examples):\n",
        "    return tokenizer_distilbert(examples[\"text\"], padding=True, truncation=True)\n",
        "\n",
        "small_tokenized_dataset_distilbert = dataset_dict.map(tokenize_function_distilbert, batched=True, batch_size=16)\n",
        "data_collator_distilbert = DataCollatorWithPadding(tokenizer=tokenizer_distilbert)"
      ],
      "metadata": {
        "id": "-FjAiAfAjM7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0a3a2eff58da49179229c7c83bd33fd1",
            "0c590b1c178e49a89dab3989acb59417",
            "ef2b85c949ca4cbabc0a5c68b12df4f6",
            "d7d0784a3f584c368fa9d14239a036d8",
            "db99b16b6c764df59bbf66fecfda1e9d",
            "12d8dbd6ab5e4860ad5a133857f2b36c",
            "1e9cd34058a04d4b8d2aa450ad0d04c1",
            "dce3b2dbd631425c8773746520c8465c",
            "4e43fa36e3f045c0bf24c8d82f5bbb7b",
            "9a7907f686074f7d9580f6fa2814548a",
            "b2a258b98ef04389b4a48708548b12f1"
          ]
        },
        "outputId": "66405071-23fd-46c1-df7c-de3b1d1af8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/187 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a3a2eff58da49179229c7c83bd33fd1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(small_tokenized_dataset_distilbert)"
      ],
      "metadata": {
        "id": "4lBAEp1wkIAs",
        "outputId": "86b8e75c-c481-4426-e11f-7c64f3a80d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 875\n",
            "    })\n",
            "    val: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 187\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 188\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: Tokenizer RoBERTa base\n",
        "tokenizer_roberta = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "def tokenize_function_roberta(examples):\n",
        "    return tokenizer_roberta(examples[\"text\"], padding=True, truncation=True)\n",
        "\n",
        "# Apply the tokenize function to the dataset\n",
        "small_tokenized_dataset_roberta = dataset_dict.map(tokenize_function_roberta, batched=True, batch_size=16)\n",
        "\n",
        "# Create a data collator with padding\n",
        "data_collator_roberta = DataCollatorWithPadding(tokenizer=tokenizer_roberta)"
      ],
      "metadata": {
        "id": "CgY6QGNPeFbm",
        "outputId": "fb675345-0be5-43db-bc98-79b07659da2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "59a32f6e4ecf4d2ba8ad1f4c13f834ca",
            "142eb308a3864a599629e72b39730b36",
            "2efc8d841d094650b7acae60ad8b488c",
            "eef9c342e77c41889ac91c4a6a0de690",
            "6bdc228fbcf14f769febccccfb4b8ca2",
            "e11fd05f2a9040309abcdf7cf455423e",
            "f9ba1b6013824db89107939ed2d3f02f",
            "d4bde59245b04319bc9cc71b26af1019",
            "efd6c82a1b9b42878cfe5f4072165064",
            "6a62d01551f24793a85197e0bb82caa7",
            "e809c7863bae4e5ab1b440081e6a5e5d"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/187 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59a32f6e4ecf4d2ba8ad1f4c13f834ca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive to store the checkpoints in Google Drive instead of my runtime:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s16lIUnh2ylo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681859d3-b039-4caf-a2c2-0649604ede25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "8zmjixIHfCrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Distil BERT cased model:\n",
        "\n",
        "set_seed(24)\n",
        "\n",
        "model_distilbert = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-cased', num_labels=2) # 2 labels: depression/no depression\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall = evaluate.load(\"recall\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "arguments_distilbert = TrainingArguments(\n",
        "    output_dir=\"distilbert\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_steps=10,\n",
        "    num_train_epochs=5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    metric_for_best_model=\"eval_recall\", # so that the model that performs best in the recall score is loaded at the end\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=0.1,\n",
        "    overwrite_output_dir=True,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to='none',\n",
        "    seed=224\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Called at the end of validation.\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Debugging: Print shapes and values\n",
        "    #print(f\"Logits shape: {logits.shape}\")\n",
        "    #print(f\"Labels: {labels}\")\n",
        "    #print(f\"Predictions: {predictions}\")\n",
        "\n",
        "    # Scikit-learn for metric computation\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    prec = precision_score(labels, predictions, average=\"binary\", zero_division=0)\n",
        "    rec = recall_score(labels, predictions, average=\"binary\", zero_division=0)\n",
        "    f1 = f1_score(labels, predictions, average=\"binary\", zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "\n",
        "trainer_distilbert = Trainer(\n",
        "    model=model_distilbert,\n",
        "    args=arguments_distilbert,\n",
        "    train_dataset=small_tokenized_dataset_distilbert['train'],\n",
        "    eval_dataset=small_tokenized_dataset_distilbert['val'],\n",
        "    processing_class=tokenizer_distilbert,\n",
        "    data_collator=data_collator_distilbert,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "Ha2DPBe9fDeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ae3765-3438-45e2-b3e8-e2de3bafabc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_distilbert.train()"
      ],
      "metadata": {
        "id": "k5XT5JbikYpC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79902cf4-816c-4d32-d2bf-7b5910d0abc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='275' max='275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [275/275 02:59, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.119400</td>\n",
              "      <td>0.129073</td>\n",
              "      <td>0.957219</td>\n",
              "      <td>0.978261</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.957447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.053900</td>\n",
              "      <td>0.121382</td>\n",
              "      <td>0.957219</td>\n",
              "      <td>0.968085</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.957895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.046400</td>\n",
              "      <td>0.135013</td>\n",
              "      <td>0.962567</td>\n",
              "      <td>0.968421</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.963351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.041200</td>\n",
              "      <td>0.155069</td>\n",
              "      <td>0.973262</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.973262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.017400</td>\n",
              "      <td>0.167772</td>\n",
              "      <td>0.962567</td>\n",
              "      <td>0.978495</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.962963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: (187, 2)\n",
            "Labels: [0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1\n",
            " 1 1]\n",
            "Predictions: [0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1\n",
            " 1 1]\n",
            "Logits shape: (187, 2)\n",
            "Labels: [0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1\n",
            " 1 1]\n",
            "Predictions: [0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1\n",
            " 1 1]\n",
            "Logits shape: (187, 2)\n",
            "Labels: [0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1\n",
            " 1 1]\n",
            "Predictions: [0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1\n",
            " 1 1]\n",
            "Logits shape: (187, 2)\n",
            "Labels: [0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1\n",
            " 1 1]\n",
            "Predictions: [0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1\n",
            " 1 1]\n",
            "Logits shape: (187, 2)\n",
            "Labels: [0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1\n",
            " 1 1]\n",
            "Predictions: [0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0\n",
            " 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0\n",
            " 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1\n",
            " 1 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=275, training_loss=0.09883375390009447, metrics={'train_runtime': 179.701, 'train_samples_per_second': 24.346, 'train_steps_per_second': 1.53, 'total_flos': 391548016613724.0, 'train_loss': 0.09883375390009447, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To see which model was actually the best one (which checkpoint):\n",
        "print(trainer_distilbert.state.best_model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvj-dsOL0nrN",
        "outputId": "354995d9-fe0d-46a3-d739-799f4315c71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distilbert/checkpoint-165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the RoBERTa base model:\n",
        "\n",
        "set_seed(24)\n",
        "\n",
        "model_roberta = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=2) # 2 labels: depression/no depression\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall = evaluate.load(\"recall\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "arguments_roberta = TrainingArguments(\n",
        "    output_dir=\"roberta\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_steps=10,\n",
        "    num_train_epochs=5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    metric_for_best_model=\"eval_recall\",\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=0.02,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    report_to='none',\n",
        "    seed=224\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Called at the end of validation.\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Debugging: Print shapes and values\n",
        "    #print(f\"Logits shape: {logits.shape}\")\n",
        "    #print(f\"Labels: {labels}\")\n",
        "    #print(f\"Predictions: {predictions}\")\n",
        "\n",
        "    # Scikit-learn for metric computation\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    prec = precision_score(labels, predictions, average=\"binary\", zero_division=0)\n",
        "    rec = recall_score(labels, predictions, average=\"binary\", zero_division=0)\n",
        "    f1 = f1_score(labels, predictions, average=\"binary\", zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "\n",
        "trainer_roberta = Trainer(\n",
        "    model=model_roberta,\n",
        "    args=arguments_roberta,\n",
        "    train_dataset=small_tokenized_dataset_roberta['train'],\n",
        "    eval_dataset=small_tokenized_dataset_roberta['val'],\n",
        "    processing_class=tokenizer_roberta,\n",
        "    data_collator=data_collator_roberta,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "JZk1SKKn__YF",
        "outputId": "00e3c3df-82e9-48bc-8c6b-30a07ebdd6c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the label distribution:\n",
        "print(\"Train label distribution:\", Counter(train['label']))\n",
        "print(\"Validation label distribution:\", Counter(val['label']))\n",
        "print(\"Test label distribution:\", Counter(test['label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9raT-ZESVP5g",
        "outputId": "dca4b648-e12e-4cb2-b7ff-ef2c4efc3069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train label distribution: Counter({0: 442, 1: 433})\n",
            "Validation label distribution: Counter({1: 96, 0: 91})\n",
            "Test label distribution: Counter({1: 98, 0: 90})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_roberta.train()"
      ],
      "metadata": {
        "id": "pIL06uuAALdg",
        "outputId": "3c063896-173f-4b4d-8a2a-103215366863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='275' max='275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [275/275 05:44, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.142300</td>\n",
              "      <td>0.154840</td>\n",
              "      <td>0.962567</td>\n",
              "      <td>0.989011</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.962567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.082200</td>\n",
              "      <td>0.169443</td>\n",
              "      <td>0.962567</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.962162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.084100</td>\n",
              "      <td>0.246036</td>\n",
              "      <td>0.957219</td>\n",
              "      <td>0.968085</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.957895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.040100</td>\n",
              "      <td>0.239469</td>\n",
              "      <td>0.957219</td>\n",
              "      <td>0.968085</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.957895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.036500</td>\n",
              "      <td>0.235300</td>\n",
              "      <td>0.957219</td>\n",
              "      <td>0.968085</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.957895</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=275, training_loss=0.10542573403567075, metrics={'train_runtime': 345.7583, 'train_samples_per_second': 12.653, 'train_steps_per_second': 0.795, 'total_flos': 734661566553360.0, 'train_loss': 0.10542573403567075, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To see which model was actually the best one (which checkpoint):\n",
        "print(trainer_roberta.state.best_model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnHrlBcm6Zd6",
        "outputId": "d90a4651-8495-4454-9cbf-f5d12bcbb39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/roberta/checkpoint-165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(small_tokenized_dataset_roberta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBwKzUv72KUg",
        "outputId": "dd7d5534-ff98-4c97-e470-922caea37675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 875\n",
            "    })\n",
            "    val: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 187\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 188\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(small_tokenized_dataset_distilbert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBKVTneg2PDn",
        "outputId": "a729e4d4-370c-4ccd-c987-d2cda42ab60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 875\n",
            "    })\n",
            "    val: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 187\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 188\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This code cell was used to fine-tune the weight decay hyperparameter, and does not need to be run again.\n",
        "'''\n",
        "# Fine-tuning weight decay for distilbert:\n",
        "import tempfile\n",
        "\n",
        "# Temporary directory for saving models during training\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "model_distilbert = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-cased', num_labels=2) # 2 labels: depression/no depression\n",
        "\n",
        "weight_decay_values = [0.001, 0.005, 0.01, 0.02, 0.1]\n",
        "for wd in weight_decay_values:\n",
        "    model_distilbert = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-cased', num_labels=2) # 2 labels: depression/no depression\n",
        "\n",
        "    arguments_distilbert = TrainingArguments(\n",
        "    output_dir=temp_dir,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_steps=10,\n",
        "    num_train_epochs=5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=wd,\n",
        "    load_best_model_at_end=False,\n",
        "    report_to='none',\n",
        "    seed=224,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "    model=model_distilbert,\n",
        "    args=arguments_distilbert,\n",
        "    train_dataset=small_tokenized_dataset_distilbert['train'],\n",
        "    eval_dataset=small_tokenized_dataset_distilbert['val'],\n",
        "    processing_class=tokenizer_distilbert,\n",
        "    data_collator=data_collator_distilbert,\n",
        "    compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()"
      ],
      "metadata": {
        "id": "7a3WuK6OVZKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This code cell was used to fine-tune the weight decay hyperparameter, and does not need to be run again.\n",
        "'''\n",
        "# Fine-tuning weight decay RoBERTa:\n",
        "\n",
        "model_roberta = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=2) # 2 labels: depression/no depression\n",
        "\n",
        "weight_decay_values = [0.001, 0.005, 0.01, 0.02, 0.1]\n",
        "for wd in weight_decay_values:\n",
        "    model_roberta = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=2) # 2 labels: depression/no depression\n",
        "\n",
        "    arguments_roberta = TrainingArguments(\n",
        "    output_dir=temp_dir,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_steps=10,\n",
        "    num_train_epochs=5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=wd,\n",
        "    load_best_model_at_end=False,\n",
        "    report_to='none',\n",
        "    seed=224\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "    model=model_roberta,\n",
        "    args=arguments_roberta,\n",
        "    train_dataset=small_tokenized_dataset_roberta['train'],\n",
        "    eval_dataset=small_tokenized_dataset_roberta['val'],\n",
        "    processing_class=tokenizer_roberta,\n",
        "    data_collator=data_collator_roberta,\n",
        "    compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()"
      ],
      "metadata": {
        "id": "8WZhSojafsef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "HcBAgLad57OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the final DistilBERT model saved in Drive with Trainer.evaluate() (less memory intensive):\n",
        "\n",
        "fine_tuned_model_distilbert = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/distilbert/checkpoint-165\")\n",
        "\n",
        "# Disable W&B logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Create a new Trainer instance for evaluation\n",
        "new_trainer = Trainer(\n",
        "    model=fine_tuned_model_distilbert,\n",
        "    eval_dataset=small_tokenized_dataset_distilbert[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_results = new_trainer.evaluate()\n",
        "print(test_results)\n",
        "\n",
        "# Get predictions and labels\n",
        "predictions, labels, _ = new_trainer.predict(small_tokenized_dataset_distilbert[\"test\"])\n",
        "\n",
        "# Get the predicted class (most probable class)\n",
        "predicted_classes = torch.argmax(torch.tensor(predictions), dim=-1)\n",
        "\n",
        "# Find wrongly classified samples\n",
        "wrongly_classified = []\n",
        "for i in range(len(predicted_classes)):\n",
        "    if predicted_classes[i] != labels[i]:\n",
        "        wrongly_classified.append({\n",
        "            \"text\": small_tokenized_dataset_distilbert[\"test\"][i][\"text\"],\n",
        "            \"true_label\": labels[i],\n",
        "            \"predicted_label\": predicted_classes[i]\n",
        "        })\n",
        "\n",
        "# Output the wrongly classified samples\n",
        "for example in wrongly_classified:\n",
        "    print(f\"Text: {example['text']}\")\n",
        "    print(f\"True Label: {example['true_label']}\")\n",
        "    print(f\"Predicted Label: {example['predicted_label']}\")\n",
        "    print(\"-\" * 100)\n",
        "\n",
        "# Evaluate the model on the entire test set\n",
        "test_results = new_trainer.evaluate()\n",
        "print(test_results)\n",
        "\n",
        "# This gives me results for best DistilBERT model from Drive."
      ],
      "metadata": {
        "id": "fx9uVQtt4uAJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "8b277876-7b58-44fb-cd79-10492f6ff351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.0935538038611412, 'eval_model_preparation_time': 0.0024, 'eval_accuracy': 0.973404255319149, 'eval_precision': 0.9894736842105263, 'eval_recall': 0.9591836734693877, 'eval_f1': 0.9740932642487047, 'eval_runtime': 4.7309, 'eval_samples_per_second': 39.739, 'eval_steps_per_second': 5.073}\n",
            "Text: scared that the ceiling fan will drop and decapitate me can t turn on the air condioner either scared that it might explode\n",
            "True Label: 1\n",
            "Predicted Label: 0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Text: day have passed since i last posted nothing ha improved my friend just hang with me for my stuff my family see me a a liability and useless it s midnight again and i wish i wa dead\n",
            "True Label: 1\n",
            "Predicted Label: 0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Text: i feel so much worse after talking to a counseller i swear this time i might actually do it\n",
            "True Label: 1\n",
            "Predicted Label: 0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Text: need s help with this anxiety crap\n",
            "True Label: 0\n",
            "Predicted Label: 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Text: filler text filler tezt\n",
            "True Label: 1\n",
            "Predicted Label: 0\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.0935538038611412, 'eval_model_preparation_time': 0.0024, 'eval_accuracy': 0.973404255319149, 'eval_precision': 0.9894736842105263, 'eval_recall': 0.9591836734693877, 'eval_f1': 0.9740932642487047, 'eval_runtime': 1.4782, 'eval_samples_per_second': 127.182, 'eval_steps_per_second': 16.236}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bin21Cec7-NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the final RoBERTa model saved in Drive with Trainer.evaluate() (less memory intensive):\n",
        "\n",
        "fine_tuned_model_roberta = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/roberta/checkpoint-165\")\n",
        "\n",
        "# Disable W&B logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Create a new Trainer instance for evaluation\n",
        "new_trainer = Trainer(\n",
        "    model=fine_tuned_model_roberta,\n",
        "    eval_dataset=small_tokenized_dataset_roberta[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_results = new_trainer.evaluate()\n",
        "print(test_results)\n",
        "\n",
        "# Get predictions and labels\n",
        "predictions, labels, _ = new_trainer.predict(small_tokenized_dataset_roberta[\"test\"])\n",
        "\n",
        "# Get the predicted class (most probable class)\n",
        "predicted_classes = torch.argmax(torch.tensor(predictions), dim=-1)\n",
        "\n",
        "# Find wrongly classified samples\n",
        "wrongly_classified = []\n",
        "for i in range(len(predicted_classes)):\n",
        "    if predicted_classes[i] != labels[i]:\n",
        "        wrongly_classified.append({\n",
        "            \"text\": small_tokenized_dataset_roberta[\"test\"][i][\"text\"],\n",
        "            \"true_label\": labels[i],\n",
        "            \"predicted_label\": predicted_classes[i]\n",
        "        })\n",
        "\n",
        "# Output the wrongly classified samples\n",
        "for example in wrongly_classified:\n",
        "    print(f\"Text: {example['text']}\")\n",
        "    print(f\"True Label: {example['true_label']}\")\n",
        "    print(f\"Predicted Label: {example['predicted_label']}\")\n",
        "    print(\"-\" * 100)\n",
        "\n",
        "# Evaluate the model on the entire test set\n",
        "test_results = new_trainer.evaluate()\n",
        "print(test_results)\n",
        "\n",
        "# This gives me results for best RoBERTa model from Drive."
      ],
      "metadata": {
        "id": "wOT94XYk534M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "0ebe9ccd-57fd-4c58-ee16-5f8c93aedc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.1415235996246338, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.9787234042553191, 'eval_precision': 0.9895833333333334, 'eval_recall': 0.9693877551020408, 'eval_f1': 0.979381443298969, 'eval_runtime': 2.5885, 'eval_samples_per_second': 72.628, 'eval_steps_per_second': 9.272}\n",
            "Text: scared that the ceiling fan will drop and decapitate me can t turn on the air condioner either scared that it might explode\n",
            "True Label: 1\n",
            "Predicted Label: 0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Text: day have passed since i last posted nothing ha improved my friend just hang with me for my stuff my family see me a a liability and useless it s midnight again and i wish i wa dead\n",
            "True Label: 1\n",
            "Predicted Label: 0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Text: need s help with this anxiety crap\n",
            "True Label: 0\n",
            "Predicted Label: 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Text: filler text filler tezt\n",
            "True Label: 1\n",
            "Predicted Label: 0\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.1415235996246338, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.9787234042553191, 'eval_precision': 0.9895833333333334, 'eval_recall': 0.9693877551020408, 'eval_f1': 0.979381443298969, 'eval_runtime': 2.4789, 'eval_samples_per_second': 75.841, 'eval_steps_per_second': 9.682}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisations:\n",
        "\n",
        "!pip install bertviz transformers\n",
        "!pip install bertviz"
      ],
      "metadata": {
        "id": "D15eVYQXdbX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca59d07-5a98-408d-c2af-744b771d32f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertviz in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertviz) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from bertviz) (4.67.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from bertviz) (1.36.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bertviz) (2.32.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from bertviz) (2024.11.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from bertviz) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->bertviz) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: botocore<1.37.0,>=1.36.4 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (1.36.4)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (0.11.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.37.0,>=1.36.4->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0->bertviz) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.37.0,>=1.36.4->boto3->bertviz) (1.17.0)\n",
            "Requirement already satisfied: bertviz in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.11/dist-packages (from bertviz) (4.47.1)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertviz) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from bertviz) (4.67.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from bertviz) (1.36.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bertviz) (2.32.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from bertviz) (2024.11.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from bertviz) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->bertviz) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->bertviz) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=2.0->bertviz) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.37.0,>=1.36.4 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (1.36.4)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (0.11.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bertviz) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.37.0,>=1.36.4->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0->bertviz) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.37.0,>=1.36.4->boto3->bertviz) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import tensorboard as tb  #this is important to be able to store embeddings in a format so that I can use tensorflow visualiation"
      ],
      "metadata": {
        "id": "TC6p7GH6eDZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "'''\n",
        "This is the code cell where I run into the RAM issue. (and the one below for RoBERTa should be similar)\n",
        "'''\n",
        "# The following code saves the hidden states of 50 samples in the test set of all layers of this DistilBERT checkpoint:\n",
        "\n",
        "# Load model:\n",
        "fine_tuned_model_distilbert = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/distilbert/checkpoint-165\")\n",
        "\n",
        "model_inputs = tokenizer_distilbert(small_tokenized_dataset_distilbert['test']['text'][0:50], padding=True, truncation=True, return_tensors='pt')\n",
        "print(len(model_inputs[\"input_ids\"]))\n",
        "print(len(small_tokenized_dataset_distilbert['test']['text']))\n",
        "outputs = fine_tuned_model_distilbert(**model_inputs, output_hidden_states=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIvfdipKuwmB",
        "outputId": "4d390984-48c9-4523-9af9-98e42369074f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import re\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import tensorboard as tb"
      ],
      "metadata": {
        "id": "Et_29IT7YSLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for visualisation:\n",
        "\n",
        "\n",
        "path = \"results_vis_distilbert\" # creates directory, can change it to drive location\n",
        "layer=0 # sets layer i want to start from\n",
        "if not os.path.exists(path):\n",
        "  os.mkdir(path)\n",
        "\n",
        "while layer in range(len(outputs['hidden_states'])):\n",
        "  if not os.path.exists(path+'/layer_' + str(layer)):\n",
        "    os.mkdir(path+'/layer_' + str(layer))\n",
        "\n",
        "  example = 0\n",
        "  tensors = []\n",
        "  labels = []\n",
        "\n",
        "  while example in range(len(outputs['hidden_states'][layer])):\n",
        "    sp_token_position = 0\n",
        "    for token in model_inputs['input_ids'][example]:\n",
        "      if token != tokenizer_distilbert.pad_token_id and token != tokenizer_distilbert.cls_token_id: # changed this code here a bit\n",
        "        sp_token_position += 1\n",
        "      else:\n",
        "        tensor = outputs['hidden_states'][layer][example][sp_token_position]\n",
        "        tensors.append(tensor)\n",
        "        break\n",
        "\n",
        "    label = [small_tokenized_dataset_distilbert['test']['text'][example],str(small_tokenized_dataset_distilbert['test']['label'][example])]\n",
        "    labels.append(label)\n",
        "    example +=1\n",
        "\n",
        "  writer=SummaryWriter(path+'/layer_' + str(layer))\n",
        "  writer.add_embedding(torch.stack(tensors), metadata=labels, metadata_header=['text','label']) # changed \"Text\" to \"text\" and \"Emotion\" to \"label\"\n",
        "\n",
        "  layer+=1"
      ],
      "metadata": {
        "id": "ZalPaDcTfa5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load RoBERTa model:\n",
        "fine_tuned_model_roberta = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/roberta/checkpoint-165\")\n",
        "\n",
        "model_inputs = tokenizer_roberta(small_tokenized_dataset_roberta['test']['text'][0:50], padding=True, truncation=True, return_tensors='pt')\n",
        "outputs = fine_tuned_model_roberta(**model_inputs, output_hidden_states=True)"
      ],
      "metadata": {
        "id": "EjSSujNRYbDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following code saves the hidden states of 50 samples in the test set of all layers of this RoBERTa checkpoint:\n",
        "\n",
        "path = \"results_vis_roberta\" # creates directory, can change it to drive location\n",
        "layer=0 # sets layer i want to start from\n",
        "if not os.path.exists(path):\n",
        "  os.mkdir(path)\n",
        "\n",
        "while layer in range(len(outputs['hidden_states'])):\n",
        "  if not os.path.exists(path+'/layer_' + str(layer)):\n",
        "    os.mkdir(path+'/layer_' + str(layer))\n",
        "\n",
        "  example = 0\n",
        "  tensors = []\n",
        "  labels = []\n",
        "\n",
        "  while example in range(len(outputs['hidden_states'][layer])):\n",
        "    sp_token_position = 0\n",
        "    for token in model_inputs['input_ids'][example]:\n",
        "      if token != tokenizer_roberta.pad_token_id and token != tokenizer_roberta.cls_token_id: # changed this code here a bit\n",
        "        sp_token_position += 1\n",
        "      else:\n",
        "        tensor = outputs['hidden_states'][layer][example][sp_token_position]\n",
        "        tensors.append(tensor)\n",
        "        break\n",
        "\n",
        "    label = [small_tokenized_dataset_roberta['test']['text'][example],str(small_tokenized_dataset_roberta['test']['label'][example])]\n",
        "    labels.append(label)\n",
        "    example +=1\n",
        "\n",
        "  writer=SummaryWriter(path+'/layer_' + str(layer))\n",
        "  writer.add_embedding(torch.stack(tensors), metadata=labels, metadata_header=['text','label']) # changed \"Text\" to \"text\" and \"Emotion\" to \"label\"\n",
        "\n",
        "  layer+=1"
      ],
      "metadata": {
        "id": "lFkW9TnsbZrz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}