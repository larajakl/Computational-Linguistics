{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNldJRKnxxmztuIhzw9j0u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larajakl/Computational-Linguistics/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfvys8hUc0FJ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install accelerate --upgrade\n",
        "!pip install optuna\n",
        "!pip install optuna-integration[pytorch_lightning]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from transformers import set_seed"
      ],
      "metadata": {
        "id": "NbU_Zj4ndE2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"mrjunos/depression-reddit-cleaned\")\n",
        "\n",
        "set_seed(24)\n"
      ],
      "metadata": {
        "id": "hpQXiCzKdHtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just take the first n tokens for speed on CPU\n",
        "def truncate(example):\n",
        "    return {\n",
        "        'text': \" \".join(example['text'].split()[:100]),\n",
        "        'label': example['label']\n",
        "    }\n",
        "\n",
        "# Random examples for train, validation and test\n",
        "# Limit the dataset to the first 200 entries, JUST FOR NOW (ADAPT THESE LINES LATER)\n",
        "subset_dataset = dataset['train'].select(range(200))\n",
        "# Define the train/val/test split proportions:\n",
        "train_ratio, val_ratio = 0.8, 0.1  # 80% train, 10% val, 10% test\n",
        "# Shuffle the dataset once:\n",
        "shuffled_dataset = subset_dataset.shuffle(seed=24)\n",
        "# Compute the split indices:\n",
        "total_size = len(shuffled_dataset)\n",
        "train_end = int(train_ratio * total_size)\n",
        "val_end = train_end + int(val_ratio * total_size)\n",
        "# Create splits:\n",
        "train = shuffled_dataset.select(range(train_end)).map(truncate)\n",
        "val = shuffled_dataset.select(range(train_end, val_end)).map(truncate)\n",
        "test = shuffled_dataset.select(range(val_end, total_size)).map(truncate)\n",
        "\n",
        "# Print the sizes of the splits:\n",
        "print(f\"Train size: {len(train)}, Validation size: {len(val)}, Test size: {len(test)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ndIlGk7gddMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(shuffled_dataset)"
      ],
      "metadata": {
        "id": "8T2YiuqkkER9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Distill BERT cased\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-cased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=True, truncation=True)\n",
        "\n",
        "small_tokenized_dataset = shuffled_dataset.map(tokenize_function, batched=True, batch_size=16)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "-FjAiAfAjM7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(small_tokenized_dataset)"
      ],
      "metadata": {
        "id": "4lBAEp1wkIAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: RoBERTa base\n",
        "\n"
      ],
      "metadata": {
        "id": "CgY6QGNPeFbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "8zmjixIHfCrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(24)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-cased', num_labels=2)\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "arguments = TrainingArguments(\n",
        "    output_dir=\"sample_cl_trainer-retrain\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_steps=8, # because 8 times 16 is 128\n",
        "    num_train_epochs=5,\n",
        "    eval_strategy=\"epoch\", # means it runs validation at the end of each epoch\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to='none',\n",
        "    seed=224\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Called at the end of validation. Gives accuracy\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # calculates the accuracy\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=arguments,\n",
        "    train_dataset=small_tokenized_dataset['train'],\n",
        "    eval_dataset=small_tokenized_dataset['val'], # change to test when you do your final evaluation!\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "Ha2DPBe9fDeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "k5XT5JbikYpC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}